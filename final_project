CMPS 4720
Dr. Kordjamshidi
Chloe Chen
Personal project

Machine Learning for Toxic Comment Classification

Introduction
In the Internet age, posting and commenting has become a large part of people’s daily lives. While commenting is an effective way of expressing one’s thoughts and opinions, the threat of abuse and harassment online stops many people from expressing themselves and from seeking different opinions. Platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut down user comments. 

Objective
Although humans have the best judgment on identifying a toxic comment, manually labeling these toxic comments is both labor-heavy and time-consuming. Machine learning is therefore suitable for the task, and the goal of the project is to build a model that’s capable of detecting different types of toxicity like threats, obscenity, insults, and identity-based hate.

Data
The data used for this project comes from the Kaggle competition “Toxic Comment Classification Challenge”. The dataset consists of a large number of Wikipedia comments that have been labeled by human raters for toxic behavior. The output space are six types of toxicity, which are: toxic, severe toxic, obscene, threat, insult, and identity hate. The appropriate learning method will be supervised learning, since the labels are predefined.

References
https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/
